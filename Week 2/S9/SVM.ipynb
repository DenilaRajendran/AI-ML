{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57131302-5c13-4c2d-a0ea-5c4bfc97d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The LinearSVC class also has a number of hyperparameters that you can adjust to control the behavior of the model. For example, you can use the C hyperparameter to control the regularization strength, which determines how much the model is allowed to overfit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ac98c1-519b-4a55-ac92-48353811620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "def load_data(): \n",
    "\t# Load your data here \n",
    "\tX, y = make_classification(n_samples=1000, \n",
    "\t\t\t\t\t\t\tn_features=4, random_state=42) \n",
    "\n",
    "\t# Split the data into training and test sets \n",
    "\tX_train, X_test, y_train, y_test = train_test_split( \n",
    "\t\tX, y, test_size=0.2, random_state=42) \n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test \n",
    "\n",
    "\n",
    "# Load the data and split it into training and test sets \n",
    "X_train, X_test, y_train, y_test = load_data() \n",
    "\n",
    "# Create the model \n",
    "model = LinearSVC() \n",
    "\n",
    "# Fit the model to the training data \n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# Evaluate the model on the test data \n",
    "accuracy = model.score(X_test, y_test) \n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde11138-0271-423c-88d7-c57a1cd77f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this example, we use the make_classification function to generate some synthetic data with 4 features and 1000 samples. We then split the data into training and test sets, and fit the model to the training data using the fit method. Finally, we evaluate the model on the test data using the scoring method, which returns the mean accuracy of the mode#l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d7fcda-5b7c-4409-a626-b2b458f5fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "def load_data(): \n",
    "\t# Load your data here \n",
    "\tX, y = make_classification(n_samples=1000, \n",
    "\t\t\t\t\t\t\tn_features=4, random_state=42) \n",
    "\n",
    "\t# Split the data into training and test sets \n",
    "\tX_train, X_test, y_train, y_test = train_test_split( \n",
    "\t\tX, y, test_size=0.2, random_state=42) \n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test \n",
    "\n",
    "\n",
    "# Generate some synthetic data \n",
    "X, y = make_classification(n_samples=1000, \n",
    "\t\t\t\t\t\tn_features=4, random_state=42) \n",
    "\n",
    "# Split the data into training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "\tX, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# Create the model \n",
    "model = LinearSVC(random_state=42) \n",
    "\n",
    "# Fit the model to the training data \n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# Evaluate the model on the test data \n",
    "accuracy = model.score(X_test, y_test) \n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ceeba7-9ed6-4d67-9925-7728e28f8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The SVM algorithm also has a regularization parameter, called C, which controls the trade-off between maximizing the margin and minimizing the misclassification error. A smaller value of C will result in a larger margin but may allow for more misclassifications, while a larger value of C will result in a smaller margin but fewer misclassifications.\n",
    "\n",
    "#Here, we use the load_iris function to load the iris dataset and split it into training and test sets. We then use GridSearchCV to perform a grid search over a range of values for the C hyperparameter. Finally, we evaluate the model on the test data using the score method, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b12454-6c3f-4955-9e91-8162d2357ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10}\n",
      "Best score: 0.96\n",
      "Test accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "def load_data(): \n",
    "\t# Load your data here \n",
    "\tX, y = make_classification(n_samples=1000, \n",
    "\t\t\t\t\t\tn_features=4, random_state=42) \n",
    "\n",
    "\t# Split the data into training and test sets \n",
    "\tX_train, X_test, y_train, y_test = train_test_split( \n",
    "\t\tX, y, test_size=0.2, random_state=42) \n",
    "\n",
    "\treturn X_train, X_test, y_train, y_test \n",
    "\n",
    "\n",
    "# Load the iris dataset \n",
    "X, y = load_iris(return_X_y=True) \n",
    "\n",
    "# Split the data into training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "\tX, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# Create a parameter grid for grid search \n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "\n",
    "# Create the model \n",
    "model = LinearSVC(random_state=42) \n",
    "\n",
    "# Create the grid search object \n",
    "grid_search = GridSearchCV(model, param_grid, cv=5) \n",
    "\n",
    "# Fit the grid search object to the training data \n",
    "grid_search.fit(X_train, y_train) \n",
    "\n",
    "# Print the best parameters and score \n",
    "print(\"Best parameters:\", grid_search.best_params_) \n",
    "print(\"Best score: {:.2f}\".format(grid_search.best_score_)) \n",
    "\n",
    "# Evaluate the model on the test data \n",
    "accuracy = grid_search.score(X_test, y_test) \n",
    "print(\"Test accuracy: {:.2f}\".format(accuracy)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e4c38-1ba3-4e7f-aa29-1ffa1cb6539b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
